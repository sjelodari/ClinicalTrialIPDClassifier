# -*- coding: utf-8 -*-
"""Data_splitting.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Bpa6k607I23zb1P47Q-ESNCzoKefRCtH
"""

#imports
import pandas as pd
from sklearn.model_selection import train_test_split
from google.colab import files

#load the dataset
df = pd.read_csv('df_finalized.csv')
df = df.sample(frac=1, random_state=42)
df['label_M'] = df['M_Label'].map({'Yes': 0, 'No': 2, 'Undecided': 1})
df['label_IPD'] = df['IPD Check'].map({'Yes': 0, 'No': 2, 'Undecided': 1})
selected_columns = ['label_M', 'IPD Description', 'label_IPD']
df = df[selected_columns]

"""## Annotated dataset split"""

train_val_df, test_df_AD = train_test_split(df, test_size=0.15, stratify=df['label_M'], random_state=42)
train_df_AD, val_df_AD = train_test_split(train_val_df, test_size=0.17647, stratify=train_val_df['label_M'], random_state=42) # 0.176 is roughly 15% of 0.85

# Saving these splits into new CSV files
train_df_AD.to_csv('train_dataset_AD.csv', index=False)
val_df_AD.to_csv('validation_dataset_AD.csv', index=False)
test_df_AD.to_csv('test_dataset_AD.csv', index=False)

#save the datasets

files.download('train_dataset_AD.csv')
files.download('validation_dataset_AD.csv')
files.download('test_dataset_AD.csv')

"""## Based on the IPD Check"""

# Splitting the dataset into training+validation and testing sets first
train_val_df, test_df_ipd = train_test_split(df, test_size=0.15, stratify=df['label_IPD'], random_state=42)

# Splitting the training+validation set into separate training and validation sets
train_df_ipd, val_df_ipd = train_test_split(train_val_df, test_size=0.17647, stratify=train_val_df['label_IPD'], random_state=42) # 0.176 is roughly 15% of 0.85

# You now have train_df, val_df, and test_df as your training, validation, and testing sets respectively

print("Training dataset size: ",train_df_ipd.shape)
print(train_df_ipd['label_IPD'].value_counts())
print("Validation dataset size: ",val_df_ipd.shape)
print(val_df_ipd['label_IPD'].value_counts())
print("Test dataset size: ",test_df_ipd.shape)
print(test_df_ipd['label_IPD'].value_counts())

# Saving these splits into new CSV files
train_df_ipd.to_csv('train_dataset_ipd.csv', index=False)
val_df_ipd.to_csv('validate_dataset_ipd.csv', index=False)
test_df_ipd.to_csv('test_dataset_ipd.csv', index=False)

files.download('train_dataset_ipd.csv')
files.download('validate_dataset_ipd.csv')
files.download('test_dataset_ipd.csv')